{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "noticed-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alternative-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder block based on the original paper\n",
    "def define_encoder_block(layer, filtersNo, batchnorm=True):\n",
    "    \n",
    "    # init weights from a Gaussian distribution with mean 0 and standard deviation 0.02\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    # in the original paper, all convolution kernels are (4,4), with stride 2. Stride for decoder means downsampling.\n",
    "    x = Conv2D(filtersNo, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer)\n",
    "    \n",
    "    # Conditional batch normalization (important for the first layer)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x, training=True)\n",
    "        \n",
    "    # All ReLUs in the encoder are leaky!\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "previous-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the decoder block based on the original paper\n",
    "def decoder_block(layer, skip, filtersNo, dropout=True, batch=True):\n",
    "    \n",
    "    # init weights from a Gaussian distribution with mean 0 and standard deviation 0.02\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    # in the original paper, all convolution kernels are (4,4), with stride 2. Stride for decoder means upsampling.\n",
    "    x = Conv2DTranspose(filtersNo, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer)\n",
    "\n",
    "    # All layers in the original paper have batch normalization, although we set an if statement just to play with the model\n",
    "    if batch:\n",
    "        x = BatchNormalization()(x, training=True)\n",
    "        \n",
    "    # Some decoder layers don't have dropout\n",
    "    if dropout:\n",
    "        x = Dropout(0.5)(x, training=True)\n",
    "        \n",
    "    # Merge with skip connection\n",
    "    x = Concatenate()([x, skip])\n",
    "    \n",
    "    # All ReLUs in the decoder are not leaky!\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gothic-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator based on encoder/decoder\n",
    "def define_generator(load = False):\n",
    "    \n",
    "    # init weights from a Gaussian distribution with mean 0 and standard deviation 0.02\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    # image input\n",
    "    inputImage = Input(shape=(128,128,1))\n",
    "    \n",
    "    ###### Encoder\n",
    "    \n",
    "    # C64, input (128,128,1), output (64,64,64)\n",
    "    encoderLayer1 = define_encoder_block(inputImage, 64, batchnorm=False)\n",
    "    \n",
    "    #C128, input (64,64,64), output (32,32,128)\n",
    "    encoderLayer2 = define_encoder_block(encoderLayer1, 128)\n",
    "    \n",
    "    #C256, input (32,32,128), output (16,16,256)\n",
    "    encoderLayer3 = define_encoder_block(encoderLayer2, 256)\n",
    "    \n",
    "    #C512, input (16,16,256), output (8,8,512)\n",
    "    encoderLayer4 = define_encoder_block(encoderLayer3, 512)\n",
    "    \n",
    "    #C512, input (8,8,512), output (4,4,512)\n",
    "    encoderLayer5 = define_encoder_block(encoderLayer4, 512)\n",
    "    \n",
    "    #C512, input (4,4,512), output (2,2,512)\n",
    "    encoderLayer6 = define_encoder_block(encoderLayer5, 512)\n",
    "    \n",
    "    ###### Bottleneck layer, will have an input of (2,2,512) and an output of (1,1,512)\n",
    "    bottleneck = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(encoderLayer6)\n",
    "    bottleneck = Activation('relu')(bottleneck)\n",
    "    \n",
    "    ###### Decoder, with skip connection\n",
    "    \n",
    "    #CD512\n",
    "    decoderLayer1 = decoder_block(bottleneck, encoderLayer6, 512)\n",
    "    \n",
    "    #CD512\n",
    "    decoderLayer2 = decoder_block(decoderLayer1, encoderLayer5, 512)\n",
    "    \n",
    "    #C512\n",
    "    decoderLayer3 = decoder_block(decoderLayer2, encoderLayer4, 512, dropout=False)\n",
    "    \n",
    "    #C256\n",
    "    decoderLayer4 = decoder_block(decoderLayer3, encoderLayer3, 256, dropout=False)\n",
    "    \n",
    "    #C128\n",
    "    decoderLayer5 = decoder_block(decoderLayer4, encoderLayer2, 128, dropout=False)\n",
    "    \n",
    "    #C64\n",
    "    decoderLayer6 = decoder_block(decoderLayer5, encoderLayer1, 64, dropout=False)\n",
    "    \n",
    "    # Output with tanh function, as mentioned in the original paper. Output will be (128x128x3)\n",
    "    g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(decoderLayer6)\n",
    "    outputImage = Activation('tanh')(g)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputImage, outputImage)\n",
    "    \n",
    "    if load == True:\n",
    "        model.load_weights(\"models/model.h5\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "printable-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 70x70 discriminator as in the original paper\n",
    "def define_discriminator():\n",
    "    \n",
    "    # init weights from a Gaussian distribution with mean 0 and standard deviation 0.02\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    # source image input\n",
    "    source = Input(shape=(128,128,1))\n",
    "    \n",
    "    # target image input\n",
    "    target = Input(shape=(128,128,3))\n",
    "    \n",
    "    # concatenate images channel-wise\n",
    "    merged = Concatenate()([source, target])\n",
    "    \n",
    "    # C64\n",
    "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # C128\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # C256\n",
    "    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # C512\n",
    "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # patch output\n",
    "    d = Conv2D(1, (8,8), strides=(8,8), padding='same', kernel_initializer=init)(d)\n",
    "    patch_out = Activation('sigmoid')(d)\n",
    "    patch_out = Flatten()(patch_out)\n",
    "    \n",
    "    # define model\n",
    "    model = Model([source, target], patch_out)\n",
    "    \n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "loving-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pix2Pix GAN\n",
    "def pix2pix(generator, discriminator):\n",
    "    \n",
    "    # make weights in the discriminator not trainable\n",
    "    for layer in discriminator.layers:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "            \n",
    "    # define the source image\n",
    "    source = Input(shape=(128,128,1))\n",
    "    \n",
    "    # connect the source image to the generator input\n",
    "    genOut = generator(source)\n",
    "    \n",
    "    # connect the source input and generator output to the discriminator input\n",
    "    disOut = discriminator([source, genOut])\n",
    "    \n",
    "    # src image as input, generated image and classification output\n",
    "    model = Model(source, [disOut, genOut])\n",
    "    \n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "previous-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFromDataset(trainX, trainY, samples):\n",
    "    \n",
    "    # Choose random images from both input and output\n",
    "    no = randint(0, trainX.shape[0], samples)\n",
    "    gx, gy = trainX[no], trainY[no]\n",
    "    \n",
    "    # Set y-labels to 1, as these images are from dataset\n",
    "    y = ones((samples, 1))\n",
    "    return [gx, gy], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fluid-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFromGenerator(generator, samples):\n",
    "    # Generate fake instance\n",
    "    x = generator.predict(samples)\n",
    "    \n",
    "    # Labels will be zero because they come from the generator\n",
    "    y = zeros((len(x), 1))\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "awful-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(step, g_model, trainX, trainY, n_samples=5):\n",
    "    # select a sample of input images\n",
    "    [X_realA, X_realB], _ = generateFromDataset(trainX, trainY, n_samples)\n",
    "    \n",
    "    # Generate fake samples\n",
    "    X_fakeB, _ = generateFromGenerator(g_model, X_realA)\n",
    "    \n",
    "    # Plot black and white images\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(3, n_samples, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_realA[i])\n",
    "        \n",
    "    # Plot generated images\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(3, n_samples, 1 + n_samples + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_fakeB[i])\n",
    "        \n",
    "    # Plot expected output images\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_realB[i])\n",
    "        \n",
    "    # Save plot to file\n",
    "    filename1 = 'images/plot_%06d.png' % (step+1)\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    "    \n",
    "    # Save generator model\n",
    "    filename2 = 'models/model_%06d.h5' % (step+1)\n",
    "    g_model.save(filename2)\n",
    "    print('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "musical-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(discriminator, generator, gan, epochs=100000, samplesPerEpoch=250):\n",
    "    \n",
    "    # Load the data\n",
    "    bwData = load(\"Flickr8kblackandwhite1dim.npy\")\n",
    "    colorData = load(\"flickr8k_shuffled.npy\")\n",
    "    y = numpy.ones((8091,1))\n",
    "    \n",
    "    BWSplit = numpy.array_split(bwData, 2)\n",
    "    colorSplit = numpy.array_split(colorData, 2)\n",
    "    glossMin = 999\n",
    "    # manually enumerate epochs\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        # Generate real samples\n",
    "        [realX, realY], realLabel = generateFromDataset(BWSplit[0], colorSplit[0], samplesPerEpoch)\n",
    "        \n",
    "        # Generate fake samples\n",
    "        fakeY, fakeLabel = generateFromGenerator(generator, realX)\n",
    "        \n",
    "        # Update discriminator on real samples\n",
    "        realLoss = discriminator.train_on_batch([realX, realY], realLabel)\n",
    "        \n",
    "        # Update discriminator on fake samples\n",
    "        fakeLoss = discriminator.train_on_batch([realX, fakeY], fakeLabel)\n",
    "        \n",
    "        # Update generator\n",
    "        generatorLoss, _, _ = gan.train_on_batch(realX, [realLabel, realY])\n",
    "        \n",
    "        # summarize performance\n",
    "        print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, realLoss, fakeLoss, generatorLoss))\n",
    "        if glossMin > generatorLoss:\n",
    "            summarize_performance(i, generator, BWSplit[0], colorSplit[0])\n",
    "            glossMin = generatorLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "assumed-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(generator):\n",
    "    # Load the data\n",
    "    bwData = load(\"Flickr8kblackandwhite1dim.npy\")\n",
    "    colorData = load(\"flickr8k_shuffled.npy\")\n",
    "    y = numpy.ones((8091,1))\n",
    "    \n",
    "    BWSplit = numpy.array_split(bwData, 2)\n",
    "    colorSplit = numpy.array_split(colorData, 2)\n",
    "    \n",
    "    averageRed = 0\n",
    "    averageGreen = 0\n",
    "    averageBlue = 0\n",
    "    \n",
    "    generatedImages, labels = generateFromGenerator(generator, BWSplit[1])\n",
    "    \n",
    "    print(\"It will take around 2 minutes to calculate all values!\")\n",
    "    \n",
    "    for i in range(0,len(BWSplit[1])):\n",
    "        \n",
    "        gImage = generatedImages[i]\n",
    "        rImage = colorSplit[1][i]\n",
    "        \n",
    "        red = 0\n",
    "        green = 0\n",
    "        blue = 0\n",
    "        \n",
    "        for x in range(0,128):\n",
    "            for y in range(0,128):\n",
    "                red += abs(rImage[x][y][0]-gImage[x][y][0])\n",
    "                green += abs(rImage[x][y][1]-gImage[x][y][1])\n",
    "                blue += abs(rImage[x][y][2]-gImage[x][y][2])\n",
    "                \n",
    "        averageRed += (red/(128*128))\n",
    "        averageGreen += (green/(128*128))\n",
    "        averageBlue += (blue/(128*128))\n",
    "        \n",
    "    averageRed = averageRed/len(BWSplit[1])\n",
    "    averageGreen = averageGreen/len(BWSplit[1])\n",
    "    averageBlue = averageBlue/len(BWSplit[1])\n",
    "    \n",
    "    print(averageRed)\n",
    "    print(averageGreen)\n",
    "    print(averageBlue)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "boxed-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = define_discriminator()\n",
    "g = define_generator()\n",
    "p2p = pix2pix(g,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "coated-russian",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-dc68cfff484d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp2p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-3a5a94052a9e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(discriminator, generator, gan, epochs, samplesPerEpoch)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Load the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mbwData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Flickr8kblackandwhite1dim.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mcolorData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"flickr8k_shuffled.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8091\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[1;32m--> 440\u001b[1;33m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[1;31m# Try a pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m             \u001b[1;31m# We can use the fast fromfile() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m             \u001b[1;31m# This is not a real file. We have to read it the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(d,g,p2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "attached-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = define_generator(load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "placed-simon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will take around 2 minutes to calculate all values!\n",
      "-0.0011209469031812087\n",
      "0.0006806952284798942\n",
      "0.0013514689952670046\n"
     ]
    }
   ],
   "source": [
    "test(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-motivation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
