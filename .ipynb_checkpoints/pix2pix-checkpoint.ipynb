{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "noticed-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alternative-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder block based on the original paper\n",
    "def define_encoder_block(layer, filtersNo, batchnorm=True):\n",
    "    \n",
    "    # init weights from a Gaussian distribution with mean 0 and standard deviation 0.02\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    # in the original paper, all convolution kernels are (4,4), with stride 2. Stride for decoder means downsampling.\n",
    "    x = Conv2D(filtersNo, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer)\n",
    "    \n",
    "    # Conditional batch normalization (important for the first layer)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x, training=True)\n",
    "        \n",
    "    # All ReLUs in the encoder are leaky!\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "previous-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the decoder block based on the original paper\n",
    "def decoder_block(layer, skip, filtersNo, dropout=True, batch=True):\n",
    "    \n",
    "    # init weights from a Gaussian distribution with mean 0 and standard deviation 0.02\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    # in the original paper, all convolution kernels are (4,4), with stride 2. Stride for decoder means upsampling.\n",
    "    x = Conv2DTranspose(filtersNo, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer)\n",
    "\n",
    "    # All layers in the original paper have batch normalization, although we set an if statement just to play with the model\n",
    "    if batch:\n",
    "        x = BatchNormalization()(x, training=True)\n",
    "        \n",
    "    # Some decoder layers don't have dropout\n",
    "    if dropout:\n",
    "        x = Dropout(0.5)(x, training=True)\n",
    "        \n",
    "    # Merge with skip connection\n",
    "    x = Concatenate()([x, skip])\n",
    "    \n",
    "    # All ReLUs in the decoder are not leaky!\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "gothic-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator based on encoder/decoder\n",
    "def define_generator():\n",
    "    \n",
    "    # init weights from a Gaussian distribution with mean 0 and standard deviation 0.02\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    # image input\n",
    "    inputImage = Input(shape=(128,128,1))\n",
    "    \n",
    "    ###### Encoder\n",
    "    \n",
    "    # C64, input (128,128,1), output (64,64,64)\n",
    "    encoderLayer1 = define_encoder_block(inputImage, 64, batchnorm=False)\n",
    "    \n",
    "    #C128, input (64,64,64), output (32,32,128)\n",
    "    encoderLayer2 = define_encoder_block(encoderLayer1, 128)\n",
    "    \n",
    "    #C256, input (32,32,128), output (16,16,256)\n",
    "    encoderLayer3 = define_encoder_block(encoderLayer2, 256)\n",
    "    \n",
    "    #C512, input (16,16,256), output (8,8,512)\n",
    "    encoderLayer4 = define_encoder_block(encoderLayer3, 512)\n",
    "    \n",
    "    #C512, input (8,8,512), output (4,4,512)\n",
    "    encoderLayer5 = define_encoder_block(encoderLayer4, 512)\n",
    "    \n",
    "    #C512, input (4,4,512), output (2,2,512)\n",
    "    encoderLayer6 = define_encoder_block(encoderLayer5, 512)\n",
    "    \n",
    "    ###### Bottleneck layer, will have an input of (2,2,512) and an output of (1,1,512)\n",
    "    bottleneck = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(encoderLayer6)\n",
    "    bottleneck = Activation('relu')(bottleneck)\n",
    "    \n",
    "    ###### Decoder, with skip connection\n",
    "    \n",
    "    #CD512\n",
    "    decoderLayer1 = decoder_block(bottleneck, encoderLayer6, 512)\n",
    "    \n",
    "    #CD512\n",
    "    decoderLayer2 = decoder_block(decoderLayer1, encoderLayer5, 512)\n",
    "    \n",
    "    #C512\n",
    "    decoderLayer3 = decoder_block(decoderLayer2, encoderLayer4, 512, dropout=False)\n",
    "    \n",
    "    #C256\n",
    "    decoderLayer4 = decoder_block(decoderLayer3, encoderLayer3, 256, dropout=False)\n",
    "    \n",
    "    #C128\n",
    "    decoderLayer5 = decoder_block(decoderLayer4, encoderLayer2, 128, dropout=False)\n",
    "    \n",
    "    #C64\n",
    "    decoderLayer6 = decoder_block(decoderLayer5, encoderLayer1, 64, dropout=False)\n",
    "    \n",
    "    # Output with tanh function, as mentioned in the original paper. Output will be (128x128x3)\n",
    "    g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(decoderLayer6)\n",
    "    outputImage = Activation('tanh')(g)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputImage, outputImage)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "printable-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 70x70 discriminator as in the original paper\n",
    "def define_discriminator():\n",
    "    \n",
    "    # init weights from a Gaussian distribution with mean 0 and standard deviation 0.02\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    # source image input\n",
    "    source = Input(shape=(128,128,1))\n",
    "    \n",
    "    # target image input\n",
    "    target = Input(shape=(128,128,3))\n",
    "    \n",
    "    # concatenate images channel-wise\n",
    "    merged = Concatenate()([source, target])\n",
    "    \n",
    "    # C64\n",
    "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # C128\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # C256\n",
    "    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # C512\n",
    "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # patch output\n",
    "    d = Conv2D(1, (8,8), strides=(8,8), padding='same', kernel_initializer=init)(d)\n",
    "    patch_out = Activation('sigmoid')(d)\n",
    "    patch_out = Flatten()(patch_out)\n",
    "    \n",
    "    # define model\n",
    "    model = Model([source, target], patch_out)\n",
    "    \n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "loving-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pix2Pix GAN\n",
    "def pix2pix(generator, discriminator):\n",
    "    \n",
    "    # make weights in the discriminator not trainable\n",
    "    for layer in discriminator.layers:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "            \n",
    "    # define the source image\n",
    "    source = Input(shape=(128,128,1))\n",
    "    \n",
    "    # connect the source image to the generator input\n",
    "    genOut = generator(source)\n",
    "    \n",
    "    # connect the source input and generator output to the discriminator input\n",
    "    disOut = discriminator([source, genOut])\n",
    "    \n",
    "    # src image as input, generated image and classification output\n",
    "    model = Model(source, [disOut, genOut])\n",
    "    \n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "previous-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFromDataset(trainX, trainY, samples):\n",
    "    \n",
    "    # Choose random images from both input and output\n",
    "    no = randint(0, trainX.shape[0], samples)\n",
    "    gx, gy = trainX[no], trainY[no]\n",
    "    \n",
    "    # Set y-labels to 1, as these images are from dataset\n",
    "    y = ones((samples, 1))\n",
    "    return [gx, gy], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fluid-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFromGenerator(generator, samples):\n",
    "    # Generate fake instance\n",
    "    x = generator.predict(samples)\n",
    "    \n",
    "    # Labels will be zero because they come from the generator\n",
    "    y = zeros((len(x), 1))\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "awful-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(step, g_model, trainX, trainY, n_samples=3):\n",
    "    # select a sample of input images\n",
    "    [X_realA, X_realB], _ = generateFromDataset(trainX, trainY, n_samples)\n",
    "    \n",
    "    # generate a batch of fake samples\n",
    "    X_fakeB, _ = generateFromGenerator(g_model, X_realA)\n",
    "    \n",
    "    # scale all pixels from [-1,1] to [0,1]\n",
    "    #X_realA = (X_realA + 1) / 2.0\n",
    "    #X_realB = (X_realB + 1) / 2.0\n",
    "    #X_fakeB = (X_fakeB + 1) / 2.0\n",
    "    \n",
    "    # plot real source images\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(3, n_samples, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_realA[i])\n",
    "    # plot generated target image\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(3, n_samples, 1 + n_samples + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_fakeB[i])\n",
    "    # plot real target image\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_realB[i])\n",
    "    # save plot to file\n",
    "    filename1 = 'plot_%06d.png' % (step+1)\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    "    # save the generator model\n",
    "    filename2 = 'model_%06d.h5' % (step+1)\n",
    "    g_model.save(filename2)\n",
    "    print('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "musical-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(discriminator, generator, gan, epochs=100000, samplesPerEpoch=250):\n",
    "    \n",
    "    # Load the data\n",
    "    bwData = load(\"Flickr8kblackandwhite1dim.npy\")\n",
    "    colorData = load(\"flickr8k_shuffled.npy\")\n",
    "    y = numpy.ones((8091,1))\n",
    "    \n",
    "    BWSplit = numpy.array_split(bwData, 2)\n",
    "    colorSplit = numpy.array_split(colorData, 2)\n",
    "    \n",
    "    # manually enumerate epochs\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        # Generate real samples\n",
    "        [realX, realY], realLabel = generateFromDataset(BWSplit[0], colorSplit[0], samplesPerEpoch)\n",
    "        \n",
    "        # Generate fake samples\n",
    "        fakeY, fakeLabel = generateFromGenerator(generator, realX)\n",
    "        \n",
    "        # Update discriminator on real samples\n",
    "        realLoss = discriminator.train_on_batch([realX, realY], realLabel)\n",
    "        \n",
    "        # Update discriminator on fake samples\n",
    "        fakeLoss = discriminator.train_on_batch([realX, fakeY], fakeLabel)\n",
    "        \n",
    "        # Update generator\n",
    "        generatorLoss, _, _ = gan.train_on_batch(realX, [realLabel, realY])\n",
    "        \n",
    "        # summarize performance\n",
    "        print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, realLoss, fakeLoss, generatorLoss))\n",
    "        if i*samplesPerEpoch % 2500 == 0:\n",
    "            summarize_performance(i, generator, BWSplit[0], colorSplit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "boxed-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = define_discriminator()\n",
    "g = define_generator()\n",
    "p2p = pix2pix(g,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-russian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, d1[0.006] d2[0.001] g[14.429]\n",
      ">Saved: plot_000001.png and model_000001.h5\n",
      ">2, d1[0.005] d2[0.008] g[13.714]\n",
      ">3, d1[0.004] d2[0.007] g[10.899]\n",
      ">4, d1[0.003] d2[0.011] g[10.149]\n",
      ">5, d1[0.003] d2[0.010] g[10.146]\n",
      ">6, d1[0.003] d2[0.030] g[9.923]\n",
      ">7, d1[0.005] d2[0.022] g[9.728]\n",
      ">8, d1[0.003] d2[0.008] g[9.675]\n",
      ">9, d1[0.006] d2[0.001] g[9.487]\n",
      ">10, d1[0.005] d2[0.015] g[9.695]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">11, d1[0.002] d2[0.088] g[9.441]\n",
      ">Saved: plot_000011.png and model_000011.h5\n",
      ">12, d1[0.006] d2[0.001] g[9.503]\n",
      ">13, d1[0.006] d2[0.011] g[9.354]\n",
      ">14, d1[0.011] d2[0.000] g[9.436]\n",
      ">15, d1[0.007] d2[0.001] g[9.441]\n",
      ">16, d1[0.006] d2[0.001] g[9.008]\n",
      ">17, d1[0.004] d2[0.081] g[9.307]\n",
      ">18, d1[0.008] d2[0.000] g[8.824]\n",
      ">19, d1[0.015] d2[0.000] g[9.347]\n",
      ">20, d1[0.005] d2[0.001] g[9.460]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">21, d1[0.005] d2[0.001] g[13.215]\n",
      ">Saved: plot_000021.png and model_000021.h5\n",
      ">22, d1[0.002] d2[0.000] g[17.613]\n",
      ">23, d1[0.003] d2[0.000] g[16.984]\n",
      ">24, d1[0.002] d2[0.000] g[12.467]\n",
      ">25, d1[0.002] d2[0.001] g[13.487]\n",
      ">26, d1[0.002] d2[0.023] g[9.874]\n",
      ">27, d1[0.002] d2[0.002] g[9.391]\n",
      ">28, d1[0.003] d2[0.035] g[9.592]\n",
      ">29, d1[0.004] d2[0.222] g[9.496]\n",
      ">30, d1[0.069] d2[0.008] g[9.996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">31, d1[0.826] d2[0.000] g[19.382]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: plot_000031.png and model_000031.h5\n",
      ">32, d1[5.263] d2[0.095] g[10.240]\n",
      ">33, d1[1.001] d2[2.065] g[9.222]\n",
      ">34, d1[0.244] d2[0.988] g[11.169]\n",
      ">35, d1[1.724] d2[0.586] g[10.411]\n",
      ">36, d1[1.202] d2[1.093] g[10.289]\n",
      ">37, d1[0.836] d2[0.853] g[9.970]\n",
      ">38, d1[0.785] d2[0.470] g[9.556]\n",
      ">39, d1[0.336] d2[0.464] g[9.543]\n",
      ">40, d1[0.303] d2[0.494] g[9.478]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">41, d1[0.354] d2[0.337] g[9.466]\n",
      ">Saved: plot_000041.png and model_000041.h5\n",
      ">42, d1[0.324] d2[0.257] g[9.408]\n",
      ">43, d1[0.209] d2[0.249] g[9.238]\n",
      ">44, d1[0.201] d2[0.104] g[9.716]\n",
      ">45, d1[0.604] d2[0.330] g[8.715]\n",
      ">46, d1[0.052] d2[0.741] g[9.172]\n",
      ">47, d1[0.376] d2[0.284] g[8.896]\n",
      ">48, d1[0.117] d2[0.086] g[8.732]\n",
      ">49, d1[0.034] d2[0.222] g[9.017]\n",
      ">50, d1[0.076] d2[0.068] g[9.239]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">51, d1[0.060] d2[0.025] g[8.532]\n",
      ">Saved: plot_000051.png and model_000051.h5\n",
      ">52, d1[0.031] d2[0.048] g[8.817]\n",
      ">53, d1[0.010] d2[0.062] g[8.711]\n",
      ">54, d1[0.016] d2[0.082] g[8.652]\n",
      ">55, d1[0.027] d2[0.021] g[8.640]\n",
      ">56, d1[0.017] d2[0.023] g[8.606]\n",
      ">57, d1[0.016] d2[0.012] g[8.649]\n",
      ">58, d1[0.009] d2[0.010] g[8.519]\n",
      ">59, d1[0.005] d2[0.003] g[8.409]\n",
      ">60, d1[0.008] d2[0.050] g[8.973]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">61, d1[0.007] d2[0.021] g[8.656]\n",
      ">Saved: plot_000061.png and model_000061.h5\n",
      ">62, d1[0.008] d2[0.020] g[8.617]\n",
      ">63, d1[0.012] d2[0.053] g[8.829]\n",
      ">64, d1[0.009] d2[0.009] g[8.456]\n",
      ">65, d1[0.008] d2[0.008] g[8.626]\n",
      ">66, d1[0.010] d2[0.002] g[8.185]\n",
      ">67, d1[0.006] d2[0.028] g[8.641]\n",
      ">68, d1[0.007] d2[0.005] g[8.672]\n",
      ">69, d1[0.005] d2[0.001] g[10.371]\n",
      ">70, d1[0.003] d2[0.003] g[13.125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">71, d1[0.004] d2[0.003] g[11.060]\n",
      ">Saved: plot_000071.png and model_000071.h5\n",
      ">72, d1[0.003] d2[0.004] g[12.221]\n",
      ">73, d1[0.002] d2[0.044] g[10.038]\n",
      ">74, d1[0.005] d2[0.009] g[11.716]\n",
      ">75, d1[0.005] d2[0.030] g[9.367]\n",
      ">76, d1[0.005] d2[0.014] g[9.088]\n",
      ">77, d1[0.007] d2[0.003] g[8.621]\n",
      ">78, d1[0.003] d2[0.011] g[8.576]\n",
      ">79, d1[0.004] d2[0.005] g[8.584]\n",
      ">80, d1[0.004] d2[0.003] g[8.454]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">81, d1[0.004] d2[0.002] g[8.602]\n",
      ">Saved: plot_000081.png and model_000081.h5\n",
      ">82, d1[0.002] d2[0.021] g[8.485]\n",
      ">83, d1[0.004] d2[0.084] g[8.307]\n",
      ">84, d1[0.013] d2[0.001] g[8.260]\n",
      ">85, d1[0.010] d2[0.008] g[8.485]\n",
      ">86, d1[0.009] d2[0.002] g[9.326]\n",
      ">87, d1[0.005] d2[0.000] g[13.670]\n",
      ">88, d1[0.004] d2[0.001] g[10.173]\n",
      ">89, d1[0.003] d2[0.002] g[13.736]\n",
      ">90, d1[0.003] d2[0.003] g[12.899]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">91, d1[0.004] d2[0.004] g[9.480]\n",
      ">Saved: plot_000091.png and model_000091.h5\n",
      ">92, d1[0.002] d2[0.012] g[9.029]\n",
      ">93, d1[0.002] d2[0.001] g[8.694]\n",
      ">94, d1[0.002] d2[0.010] g[8.672]\n",
      ">95, d1[0.002] d2[0.001] g[8.331]\n",
      ">96, d1[0.002] d2[0.001] g[8.352]\n",
      ">97, d1[0.002] d2[0.013] g[8.461]\n",
      ">98, d1[0.002] d2[0.001] g[8.090]\n",
      ">99, d1[0.002] d2[0.002] g[8.218]\n",
      ">100, d1[0.003] d2[0.004] g[8.364]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">101, d1[0.001] d2[0.005] g[8.151]\n",
      ">Saved: plot_000101.png and model_000101.h5\n",
      ">102, d1[0.002] d2[0.003] g[8.360]\n",
      ">103, d1[0.003] d2[0.006] g[8.181]\n",
      ">104, d1[0.002] d2[0.001] g[8.018]\n",
      ">105, d1[0.002] d2[0.001] g[8.406]\n",
      ">106, d1[0.002] d2[0.001] g[7.948]\n",
      ">107, d1[0.002] d2[0.003] g[8.218]\n",
      ">108, d1[0.002] d2[0.001] g[7.974]\n",
      ">109, d1[0.002] d2[0.001] g[8.115]\n",
      ">110, d1[0.001] d2[0.009] g[7.965]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">111, d1[0.001] d2[0.001] g[7.920]\n",
      ">Saved: plot_000111.png and model_000111.h5\n",
      ">112, d1[0.002] d2[0.003] g[8.306]\n",
      ">113, d1[0.001] d2[0.001] g[8.178]\n",
      ">114, d1[0.001] d2[0.001] g[7.881]\n",
      ">115, d1[0.002] d2[0.000] g[8.348]\n",
      ">116, d1[0.001] d2[0.001] g[8.172]\n",
      ">117, d1[0.001] d2[0.001] g[8.084]\n",
      ">118, d1[0.001] d2[0.004] g[7.694]\n",
      ">119, d1[0.001] d2[0.001] g[8.215]\n",
      ">120, d1[0.001] d2[0.001] g[9.635]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">121, d1[0.001] d2[0.002] g[9.812]\n",
      ">Saved: plot_000121.png and model_000121.h5\n",
      ">122, d1[0.001] d2[0.001] g[10.066]\n",
      ">123, d1[0.001] d2[0.003] g[9.178]\n",
      ">124, d1[0.001] d2[0.002] g[10.739]\n",
      ">125, d1[0.001] d2[0.000] g[9.668]\n",
      ">126, d1[0.001] d2[0.005] g[9.000]\n",
      ">127, d1[0.001] d2[0.006] g[8.424]\n",
      ">128, d1[0.001] d2[0.001] g[8.375]\n",
      ">129, d1[0.001] d2[0.002] g[8.039]\n",
      ">130, d1[0.001] d2[0.008] g[8.014]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">131, d1[0.001] d2[0.001] g[8.037]\n",
      ">Saved: plot_000131.png and model_000131.h5\n",
      ">132, d1[0.001] d2[0.000] g[8.074]\n",
      ">133, d1[0.001] d2[0.003] g[8.247]\n",
      ">134, d1[0.001] d2[0.002] g[7.801]\n",
      ">135, d1[0.001] d2[0.009] g[7.881]\n",
      ">136, d1[0.001] d2[0.002] g[7.944]\n",
      ">137, d1[0.001] d2[0.013] g[7.743]\n",
      ">138, d1[0.002] d2[0.000] g[7.881]\n",
      ">139, d1[0.001] d2[0.002] g[8.212]\n",
      ">140, d1[0.002] d2[0.001] g[8.074]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">141, d1[0.001] d2[0.000] g[7.916]\n"
     ]
    }
   ],
   "source": [
    "train(d,g,p2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-steps",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
